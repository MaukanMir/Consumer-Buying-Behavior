{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Buying Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# MLP\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Model Processing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as imblearnPipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check_models(X,y):\n",
    "    \"\"\"\n",
    "    This a quick way to spot check relevant algorithms to gain an understanding of \n",
    "    the dataset and which models handle the distribution well.\n",
    "\n",
    "    Args:\n",
    "    X: Pd.Dataframe\n",
    "    y: Pd.Series\n",
    "\n",
    "    Returns:\n",
    "        _type_: Sorted dataframe on accuracy scores.\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"LDA\":LinearDiscriminantAnalysis(),\n",
    "        \"GPC\":GaussianProcessClassifier(),\n",
    "        \n",
    "        \"LogisticRegression\": LogisticRegression(),\n",
    "        \"SVC\": SVC(),\n",
    "        \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "        \n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(random_state=42),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGB\":XGBClassifier()\n",
    "    }\n",
    "    \n",
    "    X_train, X_test, y_train_encoded, y_test_encoded = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "    # Create an empty DataFrame to store model performance\n",
    "    model_performance = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train_encoded)\n",
    "        predictions = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test_encoded, predictions)\n",
    "        model_performance.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "    # For the Sequential model\n",
    "    sequential_model = Sequential()\n",
    "    sequential_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    sequential_model.add(Dense(32, activation='relu'))\n",
    "    sequential_model.add(Dense(1, activation='sigmoid'))\n",
    "    sequential_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    sequential_model.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=10, verbose=0)\n",
    "    loss, accuracy = sequential_model.evaluate(X_test_scaled, y_test_encoded)\n",
    "    model_performance.append({\n",
    "        \"Model\": \"Sequential\",\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "    # Convert the model_performance to a DataFrame\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def f2_measure(y_true, y_pred):\n",
    "  return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "def evaluate_model(X, y, model):\n",
    "  # define evaluation procedure\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(f2_measure)\n",
    "  # evaluate model\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def labels_to_probabilities(y):\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    return probabilities\n",
    "\n",
    "def calculate_entropy(df:pd.DataFrame)-> pd.DataFrame:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      df (pd.DataFrame): Pandas DataFrame\n",
    "\n",
    "  Returns:\n",
    "      pd.DataFrame: THe Entropy level of all models\n",
    "  \"\"\"\n",
    "\n",
    "  column_entropy_info = {}\n",
    "  for col in df.columns:\n",
    "    probabilities = labels_to_probabilities(df[col])\n",
    "    entropy_value = entropy(probabilities, base=2)\n",
    "    column_entropy_info[col] = {\n",
    "          'entropy': entropy_value\n",
    "      }\n",
    "\n",
    "  return pd.DataFrame(column_entropy_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased\n",
       "0     19            19000          0\n",
       "1     35            20000          0\n",
       "2     26            43000          0\n",
       "3     27            57000          0\n",
       "4     19            76000          0\n",
       "..   ...              ...        ...\n",
       "395   46            41000          1\n",
       "396   51            23000          1\n",
       "397   50            20000          1\n",
       "398   36            33000          0\n",
       "399   49            36000          1\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"social_ads.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check For Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of null values: Age                0\n",
      "EstimatedSalary    0\n",
      "Purchased          0\n",
      "dtype: int64\n",
      "The amount of Duplicates: 33\n"
     ]
    }
   ],
   "source": [
    "print(f\"The amount of null values: {df.isna().sum()}\")\n",
    "print(f\"The amount of Duplicates: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Target class Balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, Count=229, Percentage=62.398%\n",
      "Class=1, Count=138, Percentage=37.602%\n"
     ]
    }
   ],
   "source": [
    "target = df.values[:,-1]\n",
    "\n",
    "counter = Counter(target)\n",
    "\n",
    "for k,v in counter.items():\n",
    "  per = v/len(target) * 100\n",
    "  print(\"Class=%d, Count=%d, Percentage=%.3f%%\" % (k,v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairly blanced set of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
